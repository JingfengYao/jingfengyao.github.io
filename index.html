<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jingfeng Yao (姚劲枫) </title>
    <link rel="stylesheet" href="./style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    <link rel="stylesheet" href="https://huggingface.co/front/assets/huggingface_logo.svg" crossorigin="anonymous">
</head>
<body>
    <!-- Header Section -->
    <header class="header-section">
        <h1>Jingfeng Yao (姚劲枫)</h1>
    </header>

    <!-- About Me Section -->
    <section id="about" class="content-section">
        <div class="profile-container">
            <div class="profile-photo">
                <img src="images/jingfeng.jpg" alt="Jingfeng Yao">
            </div>
            <div class="profile-info">
                <p>
                    I am Jingfeng Yao, a <strong>second-year Ph.D. student</strong> at Huazhong University of Science and Technology (HUST), supervised by <strong>Prof. Xinggang Wang</strong>. My previous research includes image matting and representation learning. Currently, my research interests focus on <strong>generative models</strong>.
                </p>
                <div class="contact-links">
                    <a href="mailto:jfyao@hust.edu.cn"><i class="fas fa-envelope"></i> Email</a>
                    <a href="https://github.com/JingfengYao"><i class="fab fa-github"></i> GitHub</a>
                    <a href="https://scholar.google.com/citations?user=4qc1qJ0AAAAJ&hl=en"><i class="fas fa-graduation-cap"></i> Google Scholar</a>
                </div>
            </div>
        </div>
    </section>

    <!-- Awards Section -->
    <section id="awards" class="content-section">
        <h2>Awards</h2>
        <ul class="awards-list">
            <li>China National Scholarship 2024<br>
                国家奖学金
                <div class="award-highlight" style="color: #666666;">
                    <i class="fas fa-award" style="color: #ffd700;"></i> The most prestigious honor for university students in China, awarded to only <strong>0.2%</strong> of candidates nationwide
                </div>
            </li>
            <li>Gold Award in China College Students' 'Internet+' Innovation and 
                Entrepreneurship Competition 2022<br>
                中国大学生"互联网+"创新创业大赛 国赛金奖
                <div class="award-highlight" style="color: #666666;">
                    <i class="fas fa-medal" style="color: #ffd700;"></i> The largest global innovation event, with a Gold Award success rate of only <strong>0.009%</strong> (about 300 out of 3.4 million projects)
                </div>
            </li>
        </ul>
    </section>

    <!-- Publications Section -->
    <section id="publications" class="content-section">
        <h2>Publications</h2>
        <div class="publication-list">

            <div class="publication-item">
                <div class="pub-thumbnail">
                    <img src="images/vavae.png" alt="Paper thumbnail">
                </div>
                <div class="pub-content">
                    <div class="pub-title">
                        <strong>Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models</strong>
                    </div>
                    <div class="pub-authors">
                        <strong>Jingfeng Yao</strong>, Xinggang Wang
                    </div>
                    <div class="pub-venue" style="color: #000000; font-style: italic;">
                        CVPR 2025 (CCF-A)
                    </div>
                    <div class="pub-highlight" style="color: #e65100;">
                        <i class="fas fa-trophy" style="color: #ffd700;"></i> Rank 1st in <a href="https://paperswithcode.com/sota/image-generation-on-imagenet-256x256">ImageNet 256×256 Generation</a> with FID=1.35 (During 2025.01-02)
                    </div>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2501.01423"><i class="fas fa-file-pdf"></i> arXiv</a>
                        <a href="https://github.com/hustvl/LightningDiT?tab=readme-ov-file"><i class="fab fa-github"></i> code</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="pub-thumbnail">
                    <img src="images/fasterdit.png" alt="Paper thumbnail">
                </div>
                <div class="pub-content">
                    <div class="pub-title">
                        <strong>FasterDiT: Towards Faster Diffusion Transformers Training without Architecture Modification</strong>
                    </div>
                    <div class="pub-authors">
                        <strong>Jingfeng Yao</strong>, Cheng Wang, Wenyu Liu, Xinggang Wang
                    </div>
                    <div class="pub-venue" style="color: #000000; font-style: italic;">
                        NeurIPS 2024 (CCF-A)
                    </div>
                    <div class="pub-highlight" style="color: #e65100;">
                        Analytical theory that observes diffusion training process from probability density function of SNR.
                    </div>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2410.10356"><i class="fas fa-file-pdf"></i> arXiv</a>
                        <a href="https://github.com/hustvl/LightningDiT?tab=readme-ov-file"><i class="fab fa-github"></i> code</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="pub-thumbnail">
                    <img src="images/evax.png" alt="Paper thumbnail">
                </div>
                <div class="pub-content">
                    <div class="pub-title">
                        <strong>EVA-X: A Foundation Model for General Chest X-ray Analysis with Self-supervised Learning</strong>
                    </div>
                    <div class="pub-authors">
                        <strong>Jingfeng Yao</strong>, Xinggang Wang, Yuehao Song, Huangxuan Zhao, Jun Ma, Yajie Chen, Wenyu Liu, Bo Wang
                    </div>
                    <div class="pub-venue" style="color: #666666; font-style: italic;">
                        arXiv preprint, 2024
                    </div>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2405.05237"><i class="fas fa-file-pdf"></i> arXiv</a>
                        <a href="https://github.com/hustvl/EVA-X"><i class="fab fa-github"></i> code</a>
                    </div>
                </div>
            </div>

            
            <div class="publication-item">
                <div class="pub-thumbnail">
                    <img src="images/lkcell.png" alt="Paper thumbnail">
                </div>
                <div class="pub-content">
                    <div class="pub-title">
                        <strong>LKCell: Efficient Cell Nuclei Instance Segmentation with Large Convolution Kernels</strong>
                    </div>
                    <div class="pub-authors">
                        Ziwei Cui*, <strong>Jingfeng Yao</strong>*, Lunbin Zeng, Juan Yang, Wenyu Liu, Xinggang Wang
                        (* denotes equal contribution)
                    </div>
                    <div class="pub-venue" style="color: #666666; font-style: italic;">
                        arXiv preprint, 2024
                    </div>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2407.18054"><i class="fas fa-file-pdf"></i> arXiv</a>
                        <a href="https://github.com/hustvl/LKCell"><i class="fab fa-github"></i> code</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="pub-thumbnail">
                    <img src="images/matteanything.png" alt="Paper thumbnail">
                </div>
                <div class="pub-content">
                    <div class="pub-title">
                        <strong>Matte Anything! Interactive Natural Image Matting with Segment Anything Models</strong>
                    </div>
                    <div class="pub-authors">
                        <strong>Jingfeng Yao</strong>, Xinggang Wang, Lang Ye, Wenyu Liu
                    </div>
                    <div class="pub-venue" style="color: #000000; font-style: italic;">
                        Image and Vision Computing (CCF-C), 2024
                    </div>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2306.04121"><i class="fas fa-file-pdf"></i> arXiv</a>
                        <a href="https://github.com/hustvl/Matte-Anything?tab=readme-ov-file"><i class="fab fa-github"></i> code</a>
                    </div>
                </div>
            </div>

            <div class="publication-item">
                <div class="pub-thumbnail">
                    <img src="images/vitmatte.png" alt="Paper thumbnail">
                </div>
                <div class="pub-content">
                    <div class="pub-title">
                        <strong>ViTMatte: Boosting Image Matting with Pretrained Plain Vision Transformers</strong>
                    </div>
                    <div class="pub-authors">
                        <strong>Jingfeng Yao</strong>, Xinggang Wang, Shusheng Yang, Baoyuan Wang
                    </div>
                    <div class="pub-venue" style="color: #000000; font-style: italic;">
                        Information Fusion (IF=14.8), 2023
                    </div>
                    <div class="pub-highlight" style="color: #e65100;">
                        <i class="fas fa-star"></i> Integrated into <a href="https://huggingface.co/docs/transformers/model_doc/vitmatte"><img src="https://huggingface.co/front/assets/huggingface_logo.svg" alt="Hugging Face" style="height: 1em; vertical-align: middle;"> Hugging Face Transformers</a> with over <a href="https://huggingface.co/hustvl/vitmatte-small-composition-1k">1,000,000 <i class="fas fa-chart-line" style="color: #e41a1c;"></i></a> monthly downloads
                    </div>
                    <div class="pub-links">
                        <a href="https://arxiv.org/abs/2305.15272"><i class="fas fa-file-pdf"></i> arXiv</a>
                        <a href="https://github.com/hustvl/ViTMatte?tab=readme-ov-file"><i class="fab fa-github"></i> code</a>
                    </div>
                </div>
            </div>

        </div>
    </section>

    <!-- Fun Facts Section -->
    <section id="fun-facts" class="content-section">
        <h2>Fun Facts</h2>
        <div class="fun-fact-list">
            <div class="fun-fact-item">
                <div class="fact-thumbnail">
                    <img src="images/volunteer.jpg" alt="Volunteer teaching">
                </div>
                <div class="fact-content">
                    <p>I spent <strong>one year as a volunteer teacher</strong> in Lincang, Yunnan Province, representing Huazhong University of Science and Technology. I taught history at Linxiang No.1 Middle School.</p>
                    <div class="fact-links">
                        <a href="https://www.thepaper.cn/newsDetail_forward_9929789" target="_blank">
                            <i class="fas fa-newspaper"></i> News Coverage
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </section>

</body>
</html>